---
title: "Regresión Lineal Múltiple"
author: "Patricia Guerrero"
date: " 02 de Agosto del 2015"
output: html_document
---

### Introducción

En el  presente trabajo vamos a realizar la planteación de un modelo mediante regresión múltiple de los archivos población1 y población2, y para ello seguiremos las instrucciones del  __trabajo final__ de la materia de __Modelos Lineales__.

  __1.__ Realice un Fork del repositorio Regresion-Lineal-Multiple.

  __2.__ Genere un archivo rlm.R, de tal forma que le permita responder las siguientes preguntas:

  __2.1__ Leer los archivos poblacion1.xlsx y poblacion2.xlsx , y analizar sus dimensiones.

Temos las siguientes datos:
Los datos de la población 1, la guardamos como data1:
```{r,echo=TRUE,eval=TRUE}
library(readxl)
data1 <- read_excel("poblacion1.xlsx",sheet = 1,col_names = TRUE,na = "")
str(data1)
names(data1)
summary(data1)
n1<-dim(data1)
n1
```
Se obtuvo 4 variables con 44 observaciones.
```{r,echo=TRUE,eval=TRUE}
library(DT)
datatable(data1)
```


Los datos de la población 2, la guardamos como data2:
```{r,echo=TRUE,eval=TRUE}
library(readxl)
data2 <- read_excel("poblacion2.xlsx",sheet = 1,col_names = TRUE,na = "")
str(data2)
names(data2)
summary(data2)
n2<-dim(data1)
n2
```
Se obtuvo 7 variables con 40 observaciones.
```{r,echo=TRUE,eval=TRUE}
library(DT)
datatable(data2)
```


  __2.2__ Una los archivos leídos en un mismo objeto llamado poblacion.
  
Realizamos la unión de las dos bases de datos dadas:
```{r,echo=TRUE,eval=TRUE}
poblacion <- merge(data1, data2, by = "identificador", suffixes = c("","")) 
str(poblacion)
names(poblacion)
summary(poblacion)
```
Se obtuvo 10 variables con 40 observaciones.
```{r,echo=TRUE,eval=TRUE}
library(DT)
datatable(poblacion)
```
Analizando la información disponemos de `r nrow(poblacion)` observaciones de `r ncol(poblacion)` variables.
Se requiere explicar la varible `r names(poblacion)[1]` en función del regresor `r names(poblacion)[2]`.

  __2.3__ Cree un código que identifique la clase de cada variable y genere diagramas de cajas para variables continuas y diagramas de barras para variables discretas.
```{r, echo=FALSE}
tipos <- numeric(ncol(poblacion))
clase <- numeric(ncol(poblacion))
for (j in 1:ncol(poblacion)){
  tipos[j] <- typeof(poblacion[,j])
  clase[j] <- class(poblacion[,j])
}
tipos
clase

for(j in 2:dim(poblacion)[2])
{ 
  if(is.numeric(poblacion[,j])==TRUE)
    { 
    print(names(poblacion)[j])
    boxplot(poblacion[,j],col="lightcoral") 
    }

  else 
    {
    #if(is.factor(poblacion[,j])==TRUE){
    print(names(poblacion)[j])
    barplot(table(poblacion[,j]),col="lightblue")
    }
}


```
  
  
  __2.4__ Cree un código que calcule automáticamente el mínimo, media, máximo, desviación estándar, primer cuartil de cada variable numérica y la frecuencia en el caso de variables categóricas.

```{r}
for(j in 2:dim(poblacion)[2]){
  if(is.numeric(poblacion[,j])==TRUE){
    
    print(names(poblacion)[j])
    print(class(poblacion[,j]))
    
    print(max(poblacion[,j]))
    print(min(poblacion[,j]))
    print(mean(poblacion[,j]))
    print(sd(poblacion[,j]))
    print(quantile(poblacion[,j],probs=seq(0,1,0.25),na.rm = FALSE))
  }else {
    
    print(names(poblacion)[j])
    print(class(poblacion[,j]))
    print(table(poblacion[,j])/dim(poblacion)[1])
  }
  
}
```
  
  __2.5__ Calcule la correlación entre la variable dependiente poblacion y cada una de las variables explicativas (numéricas).
```{r}
for(i in 3:dim(poblacion)[2]){
  if(is.numeric(poblacion[,i])==TRUE){
    correlacion<-cor(poblacion[,2],poblacion[,i])
     print(names(poblacion)[i])
    print(correlacion)
    
  }
}
```
 
La correlación de $`r substring(names(poblacion)[3],1)`$: 

$$cor(`r substring(names(poblacion)[2],1)`,`r substring(names(poblacion)[3],1)`)=-0.1577403$$


La correlación de $`r substring(names(poblacion)[4],1)`$:

$$cor(`r substring(names(poblacion)[2],1)`,`r substring(names(poblacion)[4],1)`)=0.1970906$$


La correlación de $`r substring(names(poblacion)[5],1)`$: 

$$cor(`r substring(names(poblacion)[2],1)`,`r substring(names(poblacion)[5],1)`)=-0.04686172$$


La correlación de $`r substring(names(poblacion)[6],1)`$: 

$$cor(`r substring(names(poblacion)[2],1)`,`r substring(names(poblacion)[6],1)`)=-0.07677708$$


La correlación de $`r substring(names(poblacion)[7],1)`$: 

$$cor(`r substring(names(poblacion)[2],1)`,`r substring(names(poblacion)[7],1)`)=-0.3749225$$


La correlación de $`r substring(names(poblacion)[8],1)`$: 

$$cor(`r substring(names(poblacion)[2],1)`,`r substring(names(poblacion)[8],1)`)=-0.07645301$$



  __2.6__ Considere la variable categórica serv.bas.compl con una confiabilidad del 90%, ¿ Puede asumirse que la media de la variable poblacion en el grupo serv.bas.compl: SI es distinta a la media del grupo serv.bas.compl: NO?.  Utilice la función:t.test
  
  Primero vamos a modificar la data, para transformar a "factor las columnas region y serv.bas..." para poder usar el test t(student).
```{r}
servicios<-factor(poblacion[,"serv.bas.compl"],levels=c("SI","NO"),labels=c("si","no"))
region<-factor(poblacion[,"region"],levels=c("A","B"),labels=c("a","b"))
poblacion_fac<-data.frame(poblacion[,1:7],region,servicios)
```
Luego hacemos un grafico de cajas para observar como se comporta la "poblacion" en los dos grupos
```{r, echo=FALSE}
plot(poblacion ~ servicios , data = poblacion_fac,col="lightgreen")
```

Finalmente realizamos la prueba de hipotesis para la diferencia de medias
```{r}
t.test(poblacion ~ servicios , data = poblacion_fac, conf.level=0.9)
```

La diferencia de medias es distinto de cero, es decir se rechaza la hipótesis nula.

 __2.7__ Considerando los cálculos anteriores genere el modelo de regresión lineal múltiple que mejor se ajuste a los datos. Interprete los coeficientes obtenidos.
```{r}
regresion<-lm(poblacion~var.pobl.mayor+menores.18+tasa.crimen,data=poblacion)
summary(regresion)
```
  
EL modelo obtenido es el siguiente:

$$\hat{`r substring(names(poblacion)[2],1)`} = `r regresion$coefficients[1]` + `r regresion$coefficients[2]`\hat{`r substring(names(poblacion)[3],1)`} + `r regresion$coefficients[3]`\hat{`r substring(names(poblacion)[4],1)`} `r regresion$coefficients[4]`  \hat{`r substring(names(poblacion)[7],1)`}$$

Interpretemos los coeficientes del modelo: 

* Si las variables: $\hat{`r substring(names(poblacion)[3],1)`}$, $\hat{`r substring(names(poblacion)[4],1)`}$ se mantienen constantes y la $\hat{`r substring(names(poblacion)[7],1)`}$ aumenta en una unidad (1%), se tiene que: 

la $\hat{`r substring(names(poblacion)[2],1)`}$ disminuye en promedio  `r regresion$coefficients[4]`  unidades  (`r regresion$coefficients[4]` %).

* Si las variables:  $\hat{`r substring(names(poblacion)[3],1)`}$, $\hat{`r substring(names(poblacion)[7],1)`}$ se mantienen constantes y la $\hat{`r substring(names(poblacion)[4],1)`}$ aumenta en una unidad (1%), se tiene que: 

la $\hat{`r substring(names(poblacion)[2],1)`}$ aumenta en promedio  `r regresion$coefficients[3]`  unidades  (`r regresion$coefficients[3]` %).


* Si las variables:  $\hat{`r substring(names(poblacion)[4],1)`}$, $\hat{`r substring(names(poblacion)[7],1)`}$ se mantienen constantes y la $\hat{`r substring(names(poblacion)[3],1)`}$ aumenta en una unidad (1%), se tiene que: 

la $\hat{`r substring(names(poblacion)[2],1)`}$ aumenta en promedio  `r regresion$coefficients[2]`  unidades  (`r regresion$coefficients[2]` %).


Nota: Se interpreta en términos de porcentajes debido a que las variables están expresadas como porcentajes de variación. 

  __2.8__ Interprete el $R^2$.
```{r}
summary(regresion)["r.squared"]
```

El modelo explica el `r paste(100*summary(regresion)$r.squared,"%")`, de la variabilidad de la Población.


  __2.9__ Analice la significancia de la regresión y de cada uno de los parámetros individuales.
```{r}
anova<-aov(regresion)
summary(anova)
```

Como $F=`r summary(anova)[[1]][1,4]`$ es `r tex<-"menor"; if(summary(anova)[[1]][1,4]>qf(0.95,1,(nrow(poblacion)-4))) tex<-"mayor"; tex` que $F_{1,`r (nrow(poblacion)-4)`}(\frac{\alpha}{2})= `r qf(0.95,1,(nrow(poblacion)-4))`$
`r tex<-"no rechazo"; if(summary(anova)[[1]][1,4]>qf(0.95,1,(nrow(poblacion)-4))) tex<-"rechazo"; tex`
$H_0: \beta_2=0$.

Como $F=`r summary(anova)[[1]][2,4]`$ es `r tex<-"menor"; if(summary(anova)[[1]][2,4]>qf(0.95,1,(nrow(poblacion)-4))) tex<-"mayor"; tex` que $F_{1,`r (nrow(poblacion)-4)`}(\frac{\alpha}{2})= `r qf(0.95,1,(nrow(poblacion)-4))`$
`r tex<-"no rechazo"; if(summary(anova)[[1]][2,4]>qf(0.95,1,(nrow(poblacion)-4))) tex<-"rechazo"; tex`
$H_0: \beta_3=0$.

Como $F=`r summary(anova)[[1]][3,4]`$ es `r tex<-"menor"; if(summary(anova)[[1]][3,4]>qf(0.95,1,(nrow(poblacion)-4))) tex<-"mayor"; tex` que $F_{1,`r (nrow(poblacion)-4)`}(\frac{\alpha}{2})= `r qf(0.95,1,(nrow(poblacion)-4))`$
`r tex<-"no rechazo"; if(summary(anova)[[1]][3,4]>qf(0.95,1,(nrow(poblacion)-4))) tex<-"rechazo"; tex`
$H_0: \beta_4=0$.

  __2.10__ Realice un análisis detallado de los residuos.
  
Empezamos almacenando los residuos en un vector, llamado residuos:
```{r,echo=FALSE}
residuos<-1:40  
for(i in 1:40){
  residuos[i]<-summary(regresion)[["residuals"]][i]
}
```

La tendencia del gráfico mide el efecto marginal de las variables independientes sobre la dependiente(Población).

Procedemos a graficar la variable población vs los residuos:
```{r,echo=FALSE}
plot(poblacion[,"poblacion"],residuos,col="yellow4")
```

Realizamos un histograma de los residuos:
```{r,echo=FALSE}
hist(residuos,col="orange")
```

Finalmente realizamos el gráfico de la distribución normal y agregamos la linea de tendencia:
```{r,echo=FALSE}
qqnorm(residuos, col="blue")
qqline(residuos,col="red")
```

El gráfico de probabilidad normal no rechaza la normalidad de los errores.

__3.__ Genere un informe dinámico (archivo rlm.Rmd) en el cual se detalle cada uno de los pasos ejecutados en la generación del modelo de regresión lineal múltiple, las conclusiones y resultados obtenidos. 

* Se obtuvo una data general (al unir las dos datas dadas), con 10 variables y 40 observaciones.

* No existe una alta correlación entre la población y las demás variables(var.pobl.mayor,  menores.18,	part.almz.escl,	var.ingresos,	tasa.crimen,	var.tasa.crimen). 

* El modelo que mejor se ajusta es:

$$\hat{`r substring(names(poblacion)[2],1)`} = `r regresion$coefficients[1]` + `r regresion$coefficients[2]`\hat{`r substring(names(poblacion)[3],1)`} + `r regresion$coefficients[3]`\hat{`r substring(names(poblacion)[4],1)`} `r regresion$coefficients[4]`  \hat{`r substring(names(poblacion)[7],1)`}$$

explicando el `r paste(100*summary(regresion)$r.squared,"%")` de la variabilidad de los datos de la población.

* Un dato que cabe notar es que el crimen y la población son inversamente proporcionales.

* Si las variables: $\hat{`r substring(names(poblacion)[3],1)`}$, $\hat{`r substring(names(poblacion)[4],1)`}$ se mantienen constantes y la $\hat{`r substring(names(poblacion)[7],1)`}$ aumenta en una unidad (1%), se tiene que: 

la $\hat{`r substring(names(poblacion)[2],1)`}$ disminuye en promedio  `r regresion$coefficients[4]`  unidades  (`r regresion$coefficients[4]` %).

* Si las variables:  $\hat{`r substring(names(poblacion)[3],1)`}$, $\hat{`r substring(names(poblacion)[7],1)`}$ se mantienen constantes y la $\hat{`r substring(names(poblacion)[4],1)`}$ aumenta en una unidad (1%), se tiene que: 

la $\hat{`r substring(names(poblacion)[2],1)`}$ aumenta en promedio  `r regresion$coefficients[3]`  unidades  (`r regresion$coefficients[3]` %).


* Si las variables:  $\hat{`r substring(names(poblacion)[4],1)`}$, $\hat{`r substring(names(poblacion)[7],1)`}$ se mantienen constantes y la $\hat{`r substring(names(poblacion)[3],1)`}$ aumenta en una unidad (1%), se tiene que: 

la $\hat{`r substring(names(poblacion)[2],1)`}$ aumenta en promedio  `r regresion$coefficients[2]`  unidades  (`r regresion$coefficients[2]` %).

* El gráfico de probabilidad normal no rechaza la normalidad de los errores.
